{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floating Point Arithmetic\n",
    "\n",
    "---\n",
    "\n",
    "Useful book on IEEE Floating Point standard\n",
    "\n",
    "M. Overton, Numerical Computing with IEEE Floating Point Arithmetic, SIAM Publications, Philadephia, 2001.\n",
    "\n",
    "\n",
    "__Floating Point Number System__ \n",
    "\n",
    "$x$ is a floating point number if it has the form\n",
    "\n",
    "$$\n",
    "\tx = \\pm d \\cdot \\beta^e \\quad \\beta \\in \\{ 2,10 \\}\n",
    "$$\n",
    "\n",
    "Base 2 is for general purpose computers, base 10 is for pocket calculators.\n",
    "\n",
    "$e$ is the exponent and satisfies\n",
    "\n",
    "$$\n",
    "\te_{\\min} \\leq e \\leq e_{\\max}\\quad,\n",
    "\te_{\\min} < 0 < e_{\\max}\n",
    "$$\n",
    "\n",
    "We will assume that arithmetic is in base 2, but will usually give examples in base 10.\n",
    "\n",
    "Mantissa $d$ has the form\n",
    "\n",
    "\\begin{align*}\n",
    "\td &= 0.d_1 \\dots d_t = d_1 \\beta^{-1} + d_2 \\beta^{-2}\n",
    "\t+ \\dots + d_t \\beta^{-t}\\\\\n",
    "d  &\\in \\{ 0,1\\}\\\\\n",
    "\td_1 &= 1 \\qquad \\mbox{ normalized }   \\\\\n",
    "\td_1 &= 0 \\qquad \\mbox{ unnormalized }   \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Standard form for floating point numbers is normalized except at the\n",
    "bottom of the exponent range.\n",
    "\n",
    "During input and output numbers are converted from binary to decimal\n",
    "and back.\n",
    "\n",
    "Computer arithmetic is standardized, by the IEEE 754 standard\n",
    "for binary arithmetic.  All but a few modern computers follow this standard.\n",
    "\n",
    "__Machine unit__\n",
    "\n",
    "$$\n",
    "\t\\epsilon_M = \\max_{\\lfloor \\log_2 \n",
    "    \\:|x|\\rfloor \\in\n",
    "\t[e_{\\min},e_{\\max}]} \\frac{|x - fl(x)|}{|x|}  = 2^{-t}\n",
    "$$\n",
    "\n",
    "The set\n",
    "\n",
    "$$\n",
    "\\{ x \\colon \\lfloor \\log_2 \\: |x| \\rfloor \\in [e_{min},e_{max}] \\}\n",
    "$$\n",
    "\n",
    "is the set of real numbers that are in the normalized range of floating point numbers.\n",
    "$fl(x)$ is the floating point round of $x$. Thus the __machine unit__ is the maximum relative distance\n",
    "between a real number in the floating point range and the nearest floating point number.\n",
    "\n",
    "Important examples inclue\n",
    "\n",
    "__IEEE Standard Single Precision (Float32)__  $\\beta = 2$, $t = 24$\n",
    "\n",
    "\\begin{align*}\n",
    "\t\\epsilon_M  &= 2^{-24} \\approx\t5.9605 \\times 10^{-8}\\\\\n",
    "\te_{\\min} &= - 126,\\quad e_{\\max} = 128\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "__IEEE Standard Double Precision (Float 64)__ $\\beta =2$,$t = 53$\n",
    "\n",
    "\\begin{align*}\n",
    "\t\\epsilon_M &= 2^{-53} \\approx 1.1102 \\times 10^{-16}\\\\\n",
    "    e_{\\min} &= -1022,\\quad e_{\\max} = 1024\n",
    "\\end{align*}\n",
    "\n",
    "The MATLAB `eps` command and the Julia `eps()` command give $eps = 2.2204 \\times\n",
    "10^{-16}$ which is the maximum relative spacing between two\n",
    "floating point numbers. As you can easily deduce, this number is $2\\epsilon_M$.\n",
    "\n",
    "Julia, in particular, has a type system where `Float64` type is a sub-type of `AbstractFloat`, which has four sub-types. \n",
    "In addition to types `Float64` and `Float32`, there is a type `Float16` which uses only two bytes of computer memory and type `BigFloat` which has a 256-bit mantissa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractFloat"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supertype(Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Any,1}:\n",
       " BigFloat\n",
       " Float16 \n",
       " Float32 \n",
       " Float64 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtypes(AbstractFloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000977\n",
      "1.1920929f-7\n",
      "2.220446049250313e-16\n",
      "1.727233711018888925077270372560079914223200072887256277004740694033718360632485e-77\n"
     ]
    }
   ],
   "source": [
    "for T in (Float16, Float32,Float64,BigFloat)\n",
    "    println(eps(T))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Floating Point Operations__ \n",
    "We begin with the four basic arithmetic operations, addition ($+$),subtraction ($-$),multiplication ($*$),\n",
    "and division ($/$). Suppose that __op__ is an operation such that\n",
    "\n",
    "$$\n",
    "\top \\in \\{ + , - , *,/\\}.\n",
    "$$\n",
    "\n",
    "Then, in floating point arithmetic with machine unit $\\epsilon_M$, it is reasonable to expect that\n",
    "for any two floating point numbers $x$ and $y$, we have\n",
    "\n",
    "$$\n",
    "\tfl(x\\;op\\;y) = (x \\; op\\; y)\\;(1 + \\xi),\\quad\n",
    "\t|\\xi| \\leq \\epsilon_M\n",
    "$$\n",
    "\n",
    "For division, we assume $y \\neq 0$.\n",
    "Any IEEE standard computer must follow this rule.  Rounding is one of two limitations that floating point\n",
    "arithmetic has that real arithmetic does not have. You can quickly conclude from the above rule that as long as all that we do is add numbers of the same sign, multiply, and divide, floating point results will almost always come very close to the corresponding real arithmetic results. The difficulty occurs if we either of $x$ or $y$ is rounded, they have different signs and we add or have the same signs and we subtract. \n",
    "\n",
    "That is, suppose we have\n",
    "\n",
    "$$\n",
    "\\tilde{x}= x(1+\\delta_x), \\quad \\tilde{y} = y(1+\\delta_y)\n",
    "$$\n",
    "\n",
    "where $x$ and $y$ are the exact real results of some computation and $\\tilde{x}$ and $\\tilde{y}$ are rounded floating point results with $|\\delta_x| |\\delta_y| \\leq \\delta$ for some small delta.  Suppose also that $x$ and $y$ have the same sign. If\n",
    "\n",
    "$$\n",
    "z=x+y, \\quad \\tilde{z} = fl(\\tilde{x} -\\tilde{y})\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\tilde{z} &=(\\tilde{x}-\\tilde{y})(1+\\xi), \\quad |\\xi| \\leq \\epsilon_M\\\\\n",
    "& x(1+\\delta_x)(1+\\xi) -y(1+\\delta_y)(1+\\xi) \\\\\n",
    "& x-y + \\Delta_z\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\Delta_z = (x-y)\\xi + (x\\delta_x -y\\delta_y)(1+\\xi)\n",
    "$$\n",
    "\n",
    "The best available bound on $|\\Delta_z|$ is\n",
    "\n",
    "\\begin{align*}\n",
    "|\\Delta_z| &\\leq |x-y||\\xi| + (|x||\\delta_x| + |y||\\delta_y|)(1+|\\xi|) \\\\\n",
    "& \\leq |x-y| \\epsilon_M + (|x|+|y|)\\delta(1+\\epsilon_M)\n",
    "\\end{align*}\n",
    "\n",
    "Thus\n",
    "\n",
    "\\begin{align*}\n",
    "|\\delta_z| &= \\frac{|\\tilde{z}-z|}{|z|}\\\\\n",
    "&\\leq \\epsilon_M + (1+\\epsilon_M)\\delta\\frac{|x|+|y|}{|x-y|}\n",
    "\\end{align*}\n",
    "\n",
    "If $|x-y| << |x|+|y|$, the effect of the round in the subtraction is not important, but the error from\n",
    "previous computations on $x$ and $y$ can have a huge effect. The effect is called __propagation__. It can dramatically change the result of a compuation! We will see this issue with some examples later in this lecture.\n",
    "\n",
    "Rounding is the first important limitation of floating point arithmetic.  A second limitation is the number range.\n",
    "\n",
    "\n",
    "\n",
    "__Number Ranges__\n",
    "\n",
    "Floating point arithmetic has a largest and smallest computer number. First, the largest one.\n",
    "\n",
    "__Largest Computer Number__ $\\Omega$\n",
    "\n",
    "In base $2$, with a $t$ bit mantissa, the largest computer number is\n",
    "\n",
    "$$\n",
    "\t\\Omega = (1 - 2^{-t}) \\cdot 2^{e_{\\max}}\n",
    "$$\n",
    "\n",
    "When numbers exceed $\\Omega$, they are stored as `Inf` ($\\infty$) or\n",
    "`-Inf` ($-\\infty$).\n",
    "\n",
    "\n",
    "__IEEE Standard Single Precision (Float32)__\n",
    "\n",
    "$$\n",
    "e_{\\max} = 128,  \\quad \\Omega = 3.4028\\approx 10^{38}\n",
    "$$\n",
    "\n",
    "\n",
    "__IEEE Standard Double Precision (Float64)__\n",
    "\n",
    "$$\n",
    "e_{\\max} = 1024, \\quad \\Omega = 1.79777 \\times 10^{308}\n",
    "$$\n",
    "\n",
    "The  MATLAB __realmax__ command displays this number.\n",
    "\n",
    "\n",
    "\n",
    "__Smallest Computer Number__ $\\omega$\n",
    "\n",
    "The definition of the smallest computer number is somewhat more complex.\n",
    "\n",
    "\n",
    "__IEEE Floating Point Standard__\n",
    "\n",
    "The smallest computer number is given by\n",
    "\n",
    "$$\n",
    "\\omega = 2^{1-t} 2^{e_{\\min}}.\n",
    "$$\n",
    "\n",
    "If a computation produces a number smaller in magnitude than $\\omega$, it produces what is called an \n",
    "__underflow__, it is set to $0$ or\n",
    "$-0$.  If the programmer chooses, an underflow can result in an error, but in most computations, underflows are not harmful.\n",
    "\n",
    "\n",
    "\n",
    "__IEEE Standard Single Precision (Float32)__\n",
    "\n",
    "$$\n",
    "\\omega = 2^{-23- 126} = 2^{-149} \\approx  1.4013 \\times 10^{-45}.\n",
    "$$\n",
    "\n",
    "In MATLAB, this comes from the command\n",
    "\n",
    "$$\n",
    "omega= eps('single')*realmin('single');\n",
    "$$\n",
    "\n",
    "\n",
    "__IEEE Standard Double Precision (Float64)__\n",
    "\n",
    "$$\n",
    "\\omega= 2^{-1022-52} = 2^{-1074} \\approx  4.9407 \\times 10^{-324}\n",
    "$$\n",
    "\n",
    "The appropriate MATLAB command to get this value is\n",
    "\n",
    "$$\n",
    "omega = eps*realmin.\n",
    "$$\n",
    "\n",
    "_Important and Subtle Point_ --- Numbers at the bottom of the exponent\n",
    "range are not normalized.\n",
    "\n",
    "MATLAB function `realmin` yields\n",
    "\n",
    "$$\n",
    "\t\\underline{\\omega_{useful} \\approx 2.2251 \\times 10^{-308}}\n",
    "$$\n",
    "\n",
    "Some people call this the smallest USEFUL floating point\n",
    " number since\n",
    " \n",
    "$$\n",
    "1/\\omega_{useful} \\leq \\Omega\n",
    "$$\n",
    "\n",
    "and $\\omega_{useful}$ is normalized.\n",
    "\n",
    "Smallest floating point number, $\\omega$ has the form\n",
    "\n",
    "$$\n",
    "\t0.0 \\cdots 01 \\times 2^{e_{\\min}} \\quad \\cdots\\quad\n",
    "\t\\underline{\\mbox{Gradual Underflow}}\n",
    "$$\n",
    "\n",
    "Before the IEEE standard most computers had the smallest\n",
    "floating point number as\n",
    "$$\n",
    "\t0.10 \\cdots 0 \\times 2^{e_{\\min}} \\qquad \\cdots\n",
    "\t\\mbox{ normalized}\n",
    "$$\n",
    "\n",
    "Earlier computers, (pre-1985) set numbers below this smallest 'useful' floating point number to zero.\n",
    "This change was one of the more controversial features of the IEEE standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Float16(6.104e-5),Float16(6.55e4))\n",
      "(1.1754944f-38,3.4028235f38)\n",
      "(2.2250738585072014e-308,1.7976931348623157e308)\n",
      "(2.382564904887951073216169781732674520415196125559239787955023752600945386104324e-323228497,2.09857871646738769240435811688383907063809796547335262778664622571024044777575e+323228496)\n"
     ]
    }
   ],
   "source": [
    "for T in (Float16, Float32,Float64,BigFloat)\n",
    "    println((realmin(T),realmax(T)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of code gives the actual smallest floating point number for each of these three precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0e-8\n",
      "1.0f-45\n",
      "5.0e-324\n"
     ]
    }
   ],
   "source": [
    "for T in (Float16, Float32,Float64)\n",
    "    println((realmin(T)*eps(T)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example (in decimal arithmetic) which shows why this feature made it into the IEEE standard.\n",
    "\n",
    "\n",
    "__Example__ $\\beta = 10$, $-5 \\leq e \\leq 5$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\tx & = 0.1957 \\times 10^{-5}   \\\\\n",
    "\ty & = 0.1942 \\times 10^{-5}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "Do  $fl(x - y)$ \\quad --- \\quad What happens?\n",
    "\n",
    "$$\n",
    "0.1957 \\times 10^{-5}-0.1942 \\times 10^{-5}  =0.0015 \\times 10^{-5}\n",
    "$$\n",
    "\n",
    "\n",
    "Pre-1985 philosophy --- set $x - y$ to zero\n",
    "\n",
    "Gradual Underflow stores $x - y$ as $0.0015 \\times 10^{-5}$\n",
    "\n",
    "Gradual underflow guarantees that for any two floating point numbers $x$ and $y$, \n",
    "\n",
    "$$\n",
    "fl(x - y) = 0 \\mbox{ if and only if x = y}.\n",
    "$$\n",
    "\n",
    "Now for some examples.\n",
    "\n",
    "__Interesting floating point computations__\n",
    "\n",
    "\n",
    "__Example__\n",
    "\n",
    "$$\n",
    "f(x) = \\sqrt{1 + x^2} - 1 \\quad \\mbox{$x$ near zero}.\n",
    "$$\n",
    "\n",
    "$\\underline{f(10^{-12}) = 0}$  using the formula in\n",
    "IEEE double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0e-6,5.000444502911705e-13)\n",
      "(1.0e-7,4.884981308350689e-15)\n",
      "(1.0e-8,0.0)\n",
      "(1.0e-9,0.0)\n"
     ]
    }
   ],
   "source": [
    "f(x)=sqrt(1+x^2)-1\n",
    "x=1e-6\n",
    "for k=1:4\n",
    "    println((x,f(x)))\n",
    "    x=x/10\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Better!!__\n",
    "\n",
    "Use an old \"difference of two squares\" trick.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\tf(x) & = (\\sqrt{1 + x^2} - 1) \\left( \\frac{\\sqrt{1 + x^2} + 1}{\\sqrt{1 + x^2} + 1}\\right)   \\\\\n",
    "\t& = \\frac{x^2}{\\sqrt{1+x^2} + 1}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "$\\underline{f(10^{-12}) = 0.5 \\cdot 10^{-24}}$\n",
    "\n",
    "This answer is as accurate as we can expect to get in this precision.\n",
    "We can even take this example a little farther!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0e-6,4.99999999999875e-13)\n",
      "(1.0e-7,4.999999999999987e-15)\n",
      "(1.0e-8,5.0000000000000005e-17)\n",
      "(1.0e-9,5.0e-19)\n",
      "(1.0e-10,5.0000000000000005e-21)\n",
      "(1.0000000000000001e-11,5.000000000000001e-23)\n",
      "(1.0000000000000002e-12,5.000000000000001e-25)\n",
      "(1.0000000000000002e-13,5.0000000000000016e-27)\n",
      "(1.0000000000000002e-14,5.0000000000000015e-29)\n",
      "(1.0e-15,5.0e-31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition f(Any) in module Main at In[6]:1 overwritten at In[7]:1.\n"
     ]
    }
   ],
   "source": [
    "f(x)=x^2/(1+sqrt(1+x^2))\n",
    "x=1e-6\n",
    "for k=1:10\n",
    "    println((x, f(x)))\n",
    "    x=x/10\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example Back to the Quadratic Equation__\n",
    "\n",
    "Find roots of\n",
    "$$\n",
    "\tax^2 + bx + c = 0\n",
    "$$\n",
    "\n",
    "Our classic formulas are\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\tx_1 & = \\frac{-b - \\mathrm{sign} (b) \\sqrt{b^2 - 4ac}}{2a}\n",
    "\t\\\\\n",
    "\tx_2 & =\\frac{-b +\\mathrm{sign} (b) \\sqrt{b^2 - 4ac}}{2a}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "when $\\underline{b^2 -4 ac \\geq 0}$.\n",
    "\n",
    "But we can use the \"difference of two squares\" trick again.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\t& x_2 \\cdot \\left( \\frac{b + \\mathrm{sign}(b) \\sqrt{b^2 - 4ac}}{b+ \\mathrm{sign} (b) \\sqrt{b^2 - 4ac}}\\right)\n",
    "\t\\\\\n",
    "\t& = \\frac{-b^2 + b^2 - 4ac}{2c \\cdot (b + \\mathrm{sign}(b)\\sqrt{b^2 - 4ac})}\n",
    "\t\\\\\n",
    "\t& = \\frac{-4ac}{2a\\cdot (b + \\mathrm{sign}(b) \\sqrt{b^2 -4ac})} = \\frac{-2c}{b + \\mathrm{sign}(b) \\sqrt{b^2 -4ac}}\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0e18,-3.0e-18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=1\n",
    "b=1e18\n",
    "c=3\n",
    "disc=b^2-4*a*c\n",
    "x1=(-b-sign(b)*sqrt(disc))/(2a)\n",
    "x2=-2c/(b+sign(b)*sqrt(disc))\n",
    "x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
